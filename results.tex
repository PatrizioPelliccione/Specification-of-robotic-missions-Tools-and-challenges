\newcommand{\f}[1]{\textsf{#1}\xspace}

\newcommand{\flanguage}{\f{Language}}

\newcommand{\feditor}{\f{Editor}}
\newcommand{\fsimulator}{\f{Simulator}}
\newcommand{\fdebugging}{\f{Debugging}}
\newcommand{\fspectime}{\f{SpecificationTime}}
\newcommand{\fdeployment}{\f{MissionDeployment}}
\newcommand{\fmultilang}{\f{MultiLanguageSupport}}


\newcommand{\fsemantics}{\f{Semantics}}
\newcommand{\fnotation}{\f{Notation}}
\newcommand{\flangparadigm}{\f{LanguageParadigm}}
\newcommand{\fextensibility}{\f{Extensibility}}

\newcommand{\flangconcepts}{\f{LanguageConcepts}}


\newcommand{\fflowchart}{\f{FlowChart}}
\newcommand{\fblockly}{\f{Blockly}}


\section {Analysis of Identified Environments - RQ2}

\Figref{fig:featuremodel} shows the general structure of the features we identified in our environments. 
We classified the key, top-level features into (\secref{sec:envfeatures}) capabilities and characteristics of the environments, represented by the features \feditor, \fsimulator, \fdebugging, \fspectime, \fdeployment, and \fmultilang; into (\secref{sec:langcharacteristics}) general language characteristics, represented by the feature \flanguage; and into (\secref{sec:langconcepts}) the actual concepts the languages offer to specify missions, represented by the feature \flangconcepts.
%\claudio{
%How many features have been identified in total? How many optional etc?
%How many features were identified in he brainstorming meeting? How many features were extracted from other sources?}
%\claudio{What is a general language feature? what is a Language concept?}
%\claudio{What are you going to discuss in the next two sections?}


\subsection{Specification Environment}\label{sec:envfeatures}
\noindent
We identified the following distinguishing environment characteristics that are related to the specification of missions.
%The value in brackets indicates the number of environments offering the optional feature out of 29. While simulator (10/29), multiLanguageSupport (13/29) and debugging (13/29) features are optional. Much as it is desirable to have to have a debugger and a simulator, not all the environments supported these features. 

\begin{figure}[t]
     \centering
    \includegraphics[width=\columnwidth]{fig/toplevelfeatures.png}
		  \smash{\begin{minipage}{8.3cm}
						\includegraphics[width=.18\columnwidth]{fig/legend.png}
						\vspace{2.3cm}
						\end{minipage}
			}
			\vspace{-.3cm}
      \caption{Overview of all features identified%\tb{was my version, please update, but please fix the naming of some features as I did in this figure}
      }
      \label{fig:featuremodel}
			\vspace{-.4cm}
\end{figure}

\newcommand{\fsyntacticservices}{\f{SyntacticServices}}
\newcommand{\fsemanticservices}{\f{SemanticServices}}
\newcommand{\feditingmode}{\f{EditingMode}}

\parhead{\feditor.} While the editor tooling in our environments of course offers typical editor capabilities (e.g., copy, paste or undo), we found the following distinguishing characteristics represented by the features \fsyntacticservices, \fsemanticservices, and \feditingmode, as follows.

%Besides the basic editor features such as cut, paste, and redo; we also found syntactic services, semantic services, and editing modes as editor features.

Syntactic services (feature \fsyntacticservices) support developers creating a correct abstract syntax tree (AST) of the mission specification, according to the language's abstract syntax. We found various of such services. Especially syntax highlighting with coloring is available in all environments.  %todo: verify \flyaq and \tivipe
We furthermore found a range of convenience services, such as an outline view for navigation support (e.g., in \picaxe), syntactic completion templates for users (e.g., in \edison and \ardublockly), and automated formatting (e.g., in \arcbotics, \robotmesh, and \vex).

%and invalid variable name \minibloq -> isn't that a kind of error highlighting?

%restructuring, aligning or lay-outing \cite{erdweg2013languageworkbenches} as seen in \robotmesh, \vex  -> explain what that is (didn't find in the spreadsheet)

%offer support for correct expression structure, as defined by a language to support specification of missions. The syntactic services captured include; language specific syntax coloring and symbol shapes in graphical notations, were evident in almost all the environments studied with exception of \flyaq and \tivipe where the authors were not sure. -> symbol shapes is not a syntactic service

Semantic services (feature \fsemanticservices) support developers creating an abstract syntax tree that is semantically meaningful, inspired by the definition of semantic services in~\citet{erdweg2013languageworkbenches}. We identified: auto-completion (e.g., in \vex, \trik, \picaxe, \edison);  live translation where generated code is displayed side-by-side to the graphical notation (e.g., in \easyc); error highlighting (e.g., in \edison, \aseba, \vex, \robotmesh, \blocklyprop, \minibloq, and \easyc) directly on the mission specification, for instance the indication of compile errors at the respective lines in \blocklyprop, or as a pop-up help (e.g., in \edison, \missionlab, and \choregraphe). However, more than half of the environments did not offer any semantic services. % -> verify

%and auto-help when activated enables automatic reference when blocks are selected ~\cite{ozobot} as seen in \ozoblockly, \edison.

Finally, the editing mode (feature \feditingmode) typically classifies into parser-based and projectional editing\,\cite{voelter2014projectional,berger2016pe}. In the former, the user edits the source code, which is represented by a sequence of characters in a free form. In the latter, the user's editing gestures directly change the underlying AST, which is projected using projection rules into a user-observable syntax, which can resemble textual and visual syntax, or a combination of both. \Figref{fig:easyc-sidebyside} illustrates the power of projectional editing in the environment \easyc, showing visual and textual syntax side-by-side. The typical continuous enforcement of a correct AST in projectional editing guides users towards correct mission specifications, which can also be seen as a semantic service. For all our environments, given the restriction to visual languages, every environment provides a projectional editor. However, three also offer textual languages, to be used in parallel as an alternative, relying on parser-based editing: \aseba, \vex, and \turtlebot.% and \robotc\tb{where is that stated for \robotc? can you give me the exact source?}.

\parhead{\fmultilang.} A total of 13 of our environments offer multiple languages to specify missions. While at least one visual language is supported (according to our selection criteria), many environments offer at least one more language. For instance, \picaxe provides two visual languages, based on a \fflowchart and a \fblockly notation, respectively, as well as it offers a language with a textual syntax in the style of the programming language Basic, as well as it offers the use of JavaScript.


%, and projectional mode where, the program has a standard fixed layout. In projectional editors are structured editors in which a developer works directly on the bstract syntax tree(AST) \cite{berger2016pe}, coding is done using intuitive onscreen visuals.
%\parheadit{Example} Of the 29 environment studied, only four support parser based editing mode; \aseba, \vex, \turtlebot and \robotc. This finding is not surprising since in the selection criteria, the study is biased to end-user supporting environments. 

\parhead{\fsimulator.} Ten of our environments provide simulation support to test missions before they are executed. This helps in ensuring safety and creating opportunities to train users without necessarily using the actual robots. One of the simulators, that of \missionlab, even supports multiple robots.
%The simulator either support single robot at a time or more than one robot and/or robot type. -> which ones? do we have evidence that multiple robots are supported by at least one simulator?

\parhead{\fdebugging.} A total of 13 of our environments offer debugging support. We found a variety of debugging tools, including the live monitoring of sensor data, the state of actuators, and variables in the environments \picaxe, \aseba, \trik, \flyaq, \easyc, and \edison. The environment \edison offers a box to control inputs, manipulate data, and monitor the use of variables. % -> what was 'bug-box'?
Interestingly, \makecode communicates execution traces via sound and printing text between the execution of program blocks. % -> not so clear
We also found the typical break-point mechanism to hold and monitoring executions (e.g., in \robotmesh).
Furthermore, \openroberta provides a 'check box' in the \texttt{start block}, when checked, displays current values of the connected sensor data during program execution. %menu\tb{please give me the exact source of this information (paper and position)} to confirm that the mission specification the robot's configuration matches---important since the environment supports different types of robots. 
% -> this all needs to be verified

\parhead{\fspectime.} Missions are specified either at design time or run-time. Design-time specification provides all the details about the mission before the execution starts.
 %which calls for explicit modeling of the environment.
All our environments support design-time specification. A few environments (\turtlebot, \sphero, and \choregraphe), however, also offer some remote-control functionality to intercept the mission execution at runtime. % -> verify
%with the exception of \turtlebot, \sphero and \choregraphe. For instance, in \choregraphe, different missions can be deployed on the robot at run-time. \sphero supports interaction with the robot at run-time using a Bluetooth connection. % -> I think this is wrong

\parhead{\fdeployment.} Missions, once specified, are transferred to the robots for execution. Not surprisingly, we found different combinations of media to transfer missions, including USB cable, Ethernet cable, custom cable, as well as WiFi and Bluetooth connections.
 %Environments such as \trik and \lego support USB, WiFi, and Bluetooth connections for deployment over-the-air. While \tello missions can be deployed using Bluetooth, and Wi-Fi. Most environments use either USB, Ethernet or a custom cable to deploy missions to robots. \\ 


% \textbf{items removed}
% \begin{itemize}
%     %\item file access
%     \item time has been merged as a measure of action under action types
%     \item example as an example of syntax services
%     \item formal notation (generic code, natural language text, forms, blocks, icons) and secondary notation (syntax highlighting, size, notation color, comments) as concrete features of notation.
%     \item behavior concepts with concrete features like discrete behavior and continuous behavior from language features
%     \item robot with single/multi-robot mission (swarm/team), multi-robot, single robot, robot types and connection and multi-robot types as concrete features
%     \item Mission deployment support; hardware requirements and software requirements
%     \item debugging environments; simulation, actual robot
%     \item modeling concepts and explicit modeling of environment 
% \end{itemize}





	
\subsection{General Language Characteristics}\label{sec:langcharacteristics}
As illustrated in \figref{fig:languagefeatures}, we identified the following general characteristics in which the languages differ, represented by the features: \fnotation, \fsemantics, \flangparadigm, and \fextensibility. The actual concepts offered by the languages will be discussed in \secref{sec:langconcepts}.

%The language constructs for motor, and sensor  data configurations are abstracted closer to those who are familiar to the use of the sensor than just robot engineers. For example \emph{set motor speed, obstacle detector event block (grey: ignore detector, white: object close and black: object far)}. \claudio{The previous sentences are part of the methodology} The fact that these languages support graphical notations breaks the barrier created by text notation among novice programmers, as asserted by Fernandez-Permomo et al.\cite{Fernandez-Perdomo2010}, hence increasing usability, learnability and satisfaction among end-users. \claudio{Not clear what is the point of this sentence? Here we should discuss the FM we have created}
%\tb{we need examples of domain-specific terminology in the languages, can you provide some? also, examples why you think the languages are end-user facing; why is that the case?}
%For instance, they support end users through \dots. Most (X\,\%) are also graphical.
%domain, which generalized features that support novice programmers and robotics domain, which take care of technical features for professionals in robotics or software engineering.
All the languages identified in the environments including the textual ones have been customized to support the robotics domain, for example by introducing domain specific actions. Some of the actions in \lego are stop motors, play tone in \trik, set robot's state, set top color in \aseba,  drive straight, and turn right. %in \lego are some domain specific actions.% \tb{how? give examples of domain-specific keywords and domain-specific graphical elements}.

\begin{figure}[t]
     \centering
    \includegraphics[width=.75\columnwidth]{Languagefeatures.png}
      \caption{Language Characteristics}
      \label{fig:languagefeatures}
   \end{figure}

\parhead{\fnotation.} All our environments offer languages with a domain-specific visual notation (concrete syntax) for end users. For instance, a block \emph{Motor forward} in \trik has a gear icon with a forward arrow depicting a forward-running motor. The user only specifies the motor power and the port in which the motor connects. 13 of our environments additionally offer a textual syntax

\tb{I think I now know how to write this part, will do later; got a lot of insights from looking through the data an the screenshots I took over the weekend}
%\tb{do you know for how many the textual syntax belongs to the same language (the main, visual language) and for how many it is a separate language (which could also be a gpl)?}.

\begin{itemize}
	\item Graph-based
	\item Custom block diagrams
\end{itemize}

The notation found is: (i) Blockly-based as shown in Figure \ref{metabot}, (ii) Scratch-based as shown in Figure
	\ref{scratch-marty}, (iii) forms and tables as shown in Figure \ref{fig:robotcgraphical}, or (iv) textual where End-user codes a mission using text characters.

%\tb{but thought we have graph-based and block-based as our features?}
%\begin{itemize}
%	\item Blockly-based as shown in figure \ref{metabot}%\tb{characterize what you've seen; how does it look like}
%	\item Scratch-based as shown in figure
%	\ref{scratch-marty}%\tb{characterize what you've seen; how does it look like}
%	\item forms and tables as shown in figure \ref{fig:robotcgraphical}%\tb{characterize what you've seen; how does it look like}
%	\item textual where End-user codes a mission using text characters.%\tb{characterize what you've seen; what kinds of textual notations do we have? how do they look like?}
%\end{itemize}

Some of the graphical notations used blocks, which are directly connected to each other for instance \trik, blockly, and scratch based languages. While \choregraphe, Flowol in \robotmesh, and flowchat in \picaxe use connectors between blocks to form graph like structures. %A graphical notation is either block-based or graph-based. A block-based \tb{what's the difference? briefly describe}.
Interestingly, \flyaq offers a map-based 
%\tb{so, is that classified as graph-based or block-based, or sth. else?} 
monitoring mission language to specify missions by clicking on locations where tasks will be executed. 

The textual or visual notations offered by the respective environments are summarized in \tabref{notation}. Some environments use a mix of textual and visual notations, like \easyc, as shown in \figref{fig:easyc-sidebyside}, or make use of tables and forms, as \robotc as shown in  %\figref{fig:robotctextual} and 
\figref{fig:robotcgraphical}.

\aseba: \figref{fig:aseba-vpl}

\begin{figure}[b]
	\centering
	\includegraphics[width=\columnwidth]{fig/aseba-vpl-event-action-pairs.png}
	\caption{\aseba's visual notation for its language VPL, which is an event-based language consisting of event-action pairs. One such pair is shown here.}
	\label{fig:aseba-vpl}
\end{figure}


%Textual: \edison, \choregraphe, 
%%\tb{choregraphe is definitely visual!},\swaib{the point is it also supports textual notations} 
%visual: \minibloq, \trik, \choregraphe, and mix of both text and visual \easyc \figref{fig:easyc-sidebyside} or by use of tables and forms as provided by \robotc in  %\figref{fig:robotctextual} and 
%\figref{fig:robotcgraphical}. % \tb{add screenshot}.
%The notations offered by the respective environments have been summarized in the table \ref{notation}.

%- symbol shapes in graphical notations
%- Blockly library: It has been implemented in various environments as shown in table \ref{notation}% Roberta\,\cite{OpenRoberta,PICAXE,RobotMeshStudio} \tb{make complete, where else?}

\begin{figure}[t]
	\centering
	\includegraphics[max size={0.5\textwidth}{\textheight}]{projectionalEasyC.jpg}
	\caption{Graphical and textual syntax side-by-side in \easyc's projectional editor%\tb{TODO: create better screenshot}
	}\label{fig:easyc-sidebyside}
\end{figure}

% \begin{figure}[t]
% 	\centering
% 		\includegraphics[max size={0.5\textwidth}{\textheight}]{robotCtext.png}
% 	\caption{RobotC, (a) textual \cite{Schunn2017} }
% 	\label{fig:robotctextual}
% \end{figure}

\begin{figure}[t]
	\centering
		\includegraphics[width=\columnwidth]{robotc2.png}	\caption{\robotc, graphical notation (from \cite{Admin})%\tb{quality too low; need a higher resolution image; actually, you write that you've installed it, so take a screenshot yourself (taking one yourself should always be done when possible, as opposed to copying from another paper (which requires saying explicitly 'from []' in the caption; this is also the only exception where you can refer directly to a [])}
		}
	\label{fig:robotcgraphical}
\end{figure}
%\claudio{Missing verb. Which details?} %Secondary notation services provide extra information on the marks and cues used for specification of missions, like; comments, and size of blocks~\cite{Blackwell2001}.

\input{tables/notationstable.tex}


\parhead{\fsemantics} The semantics of our languages are determined by either interpretation or compilation (target code generation). The mission specified is either semantically translated (compiled) as shown in \tabref{Codegeneration} or interpreted to preserve what is specified and what the robot actually executes. Apart from \lego, and \codelab whose missions are interpreted, all the other 27 environments generate code. \metabot generates assembly code while the rest compile generated code before robot executes the mission.\patrizio{check this sentence. who are other? What do we want to say?} \swaib{if we have 29 environments and 2 of the 29 are interpreted, then the remaining 27 (others) are compiled} \trik supports Lego Ev3, Lego NXT, pioneer kit, and the TRIK robot, even though the environment does not cross-compile as missions are robot specific. In the case of Lego EV3, missions are interpreted, with support for both USB and Bluetooth connections.
%\tb{this has nothing to do with semantics}. 
In the case of Lego NXT, besides interpretation, \trik generates Russian C language\tb{what is that? can you give me a reference to that language?} and NXT OSEK C language\tb{what is that? can you give me a reference?} \swaib{I saw Russian C and OSEK C languages as possible languages for generated code for the when running \trik. My best reference is when you install \trik. But I have not seen published documentation about them}, while in the case of TRIK robot, the environment generates Java Script, PascalABC, Python, and F\#.%\tb{why does it generate programs in so many different languages?} \swaib{Russian C, OSEK C are target languages seen in the list, however there is no much documentation about them in the tool documents. I have not figured out why TRI robot missions can be generated into several languages}. \codelab provides support for mission interpretation using Python SDK\tb{unclear, what does that mean?} \swaib{the interpreter was built using python software development kit (SDK)}.

\input{tables/codegentable.tex}

%\tb{I just checked \choregraphe, and it does not generate .NET bytecode (which would be MSIL), but it provides language bindings (an API) for .NET so that .NET programs can call API functions of NAO to control it}

%\tb{what about all the other environments?} \swaib{cross examining the data collect can help in fixing such gaps}


\parhead{\fextensibility} -
Some environments provide features for extending the language with new concepts. We classified such abstract features into two concrete features ScriptingSupport and AddLanguageConcepts. %{ can be in form of scripting support, editing graphical programming blocks or adding new language concepts using the generic language of the environment} \claudio{Check that abstract features and concreted features are defined somewhere}.
ScriptingSupport allows the creation and launching of new scripts created to handle new language constructs. This is the case for instance of the creation of  movements for NOA robot in \choregraphe.
 While AddLanguageConcepts support allows user to edit and create new blocks, for example myblock in \makeblock, creating new blocks in \tivipe, extending monitoring mission language in \flyaq. \patrizio{I don't understand the previous sentence}  Open source environments use github for communities to continuously extend the language feature e.g.: \sphero, \openroberta, and \flyaq. Environments like \easyc, \flyaq, and \missionlab provide opportunity to extend the language features using \ugh{the generic languages, not necessarily scripting or editing graphical blocks}. \patrizio{this is not clear} \swaib{In my opinion, it would be wise to treat language extension as a concrete feature without subfeatures. Otherwise I struggle to differentiate between scripting support, block editing and others which can not be easily classified as scripting support or block editing e.g. \flyaq, \missionlab and \easyc}  
%\claudio{How is this info related with the FM?} \swaib{Extension is a feature in the FM} 
\lego extends the language features by importing custom programming blocks from vendors which manufacture sensing blocks compatible with the Lego brick. However, most commercial environments, extensions  are done by the commercial companies. E.g.: \arcbotics, \edison, \blocklyprop, \vex, \robotmesh among others.

\parhead{\flangparadigm} - All our languages are DSLs as opposed to general-purpose languages (GPLs), since all incorporate keywords representing concepts pertaining to the robotics domain. However, some language also offer GPLs for programmers, in addition to their primary visual DSLs.
%defines the category of languages found in the specification environments. All languages in the selected environments are domain specific languages with a bias to robotics and software engineering domains. In the interest of end-user programming, it is desirable to see languages whose DSLs are specific to user domains like farming, or environmental management.% \claudio{What were the options? Is it really a feature?}


\input{languageconcepts.tex}